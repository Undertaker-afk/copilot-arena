{
    "pairId": "74ca40ac-a22b-49ff-af59-dba203ae3fbd",
    "completionItems": [
        {
            "completionId": "af345c49-200a-4ebd-ba68-0fe29c376410",
            "userId": "d0fdbdd90881f84353451cf61410db0fc10cd31010d6764896ab2423f56035bd",
            "timestamp": 1723321959,
            "prompt": "import os\nimport json\nimport pdb\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.image import imread\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom tqdm import tqdm\n\n# Load cached data\nif not os.path.exists(\\'../data\\'):\n    os.system(\\'gdown 1h7S6N_Rx7gdfO3ZunzErZy6H7620EbZK -O ../data.tar.gz\\')\n    os.system(\\'tar -xf ../data.tar.gz -C ../\\')\n    os.system(\\'rm ../data.tar.gz\\')\nif not os.path.exists(\\'../data/imagenet/human_readable_labels.json\\'):\n    !wget -nv -O ../data/imagenet/human_readable_labels.json -L https://raw.githubusercontent.com/anishathalye/imagenet-simple-labels/master/imagenet-simple-labels.json\n\ndata = np.load(\\'../data/imagenet/imagenet-resnet152.npz\\')\nexample_paths = os.listdir(\\'../data/imagenet/examples\\')\nsmx = data[\\'smx\\']\nlabels = data[\\'labels\\'].astype(int)\n\nidx = np.random.permutation(len(labels))\nlabels = labels[idx[:10000]]\nsmx = smx[idx[:10000]]\nprint(len(labels))\n\ndef get_thetahat_fixed(\n    h,\n    g,\n    p,\n    cost_ratio,\n    TOL=1e-20,\n):\n    xi = np.ones(len(h))\n    theta_hats = np.zeros(len(h))\n    costs = np.zeros(len(h))\n    for i in range(len(h)):\n        xi[i] = np.random.binomial(1, p)\n        costs[i] = costs[max(i-1,0)]\n        costs[i] += 1 if p == 1 else cost_ratio + xi[i]\n        theta_hats[i] = np.mean(g[:i] + (h[:i]-g[:i]) * xi[:i]/p) if i > 0 else 0\n    return theta_hats, costs\n\ndef optimal_p(VarH, EHG2, c_g, c_h, TOL=1e-20):\n    phat = np.clip(np.sqrt((c_g/c_h)/max(VarH/max(EHG2, TOL) - 1, TOL)),TOL,1)\n    return phat\n\ndef get_thetahat_active(\n    h,\n    g,\n    pis,\n    cost_ratio,\n    TOL=1e-20,\n):\n    # if pis is a float, call get_thetahat_fixed\n    if isinstance(pis, (int, float)):\n        return get_thetahat_fixed(h, g, pis, cost_ratio, TOL=TOL)\n    xi = np.ones(len(h))\n    theta_hats = np.zeros(len(h))\n    costs = np.zeros(len(h))\n    for i in range(len(h)):\n        xi[i] = np.random.binomial(1, pis[i])\n        costs[i] = costs[max(i-1,0)]\n        costs[i] += 1 if pis[i] == 1 else cost_ratio + xi[i]\n        theta_hats[i] = np.mean(g[:i] + (h[:i]-g[:i]) * xi[:i]/pis[:i]) if i > 0 else 0\n    return theta_hats, costs\n\ndef optimal_pi(u, VarH, EHG2, cost_ratio, TOL=1e-20):\n    phat = np.clip(np.sqrt(\n       np.maximum(u * cost_ratio / np.maximum(VarH - EHG2, TOL), TOL)\n    ),TOL,1)\n    return phat\n\n# Problem setup\nB = 1000\ncost_ratio = 0.01\nburnin = 100\nepsilon = 1e-20 # Min sampling probability\nTOL = 1e-20 # Numerical tolerance\nn = len(smx)\nnum_trials = 1000\nmethods = [\"oracle active\", \"optimal active\", \"optimal fixed\", 1, 0.5, 0.05]\n\ndf_list = []\nfor trial in tqdm(range(num_trials)):\n    np.random.seed(trial)\n    idx = np.random.permutation(n)\n    smx = smx[idx]\n    yhat = smx.argmax(axis=1)\n    labels = labels[idx]\n    h = (yhat == labels).astype(int)\n    g = smx.max(axis=1)\n    u = g*(1-g)\n    betas = np.linspace(0,1,10)\n    thetastar = (yhat == labels).mean()\n    for method in methods:\n        # Set random seed\n        np.random.seed(trial)\n        VarHhat = h[:burnin].var()\n        EHG2hat = ((h[:burnin] - g[:burnin])**2).mean()\n        if method == \"optimal fixed\":\n            phat = optimal_p(VarHhat, EHG2hat, cost_ratio, 1)\n        elif method == \"optimal active\": \n            phat = optimal_pi(u, VarHhat, EHG2hat, cost_ratio, TOL=TOL)\n        elif method == \"oracle active\":\n            phat = np.maximum((h-g)**2, TOL)\n        elif method == \"oracle mixing\":\n            phat_fixed = optimal_p(VarHhat, EHG2hat, cost_ratio, 1)\n            phat_active = optimal_pi(u, VarHhat, EHG2hat, cost_ratio, TOL=TOL)\n            phat = phat_fixed\n            best_mse = np.inf\n            for beta in betas:\n                _phat = beta*phat_fixed + (1-beta)*phat_active\n                _mse = (_phat.mean() + cost_ratio)*(VarHhat - EHG2hat + (((h[:burnin] - g[:burnin])**2)/_phat).mean())\n                if _mse ",
            "completion": " < best_mse:\n                    phat = _phat\n                    best_mse = _mse",
            "model": "codestral-2405"
        },
        {
            "completionId": "e491feaf-8892-4e42-bc1b-7038ffdff12d",
            "userId": "d0fdbdd90881f84353451cf61410db0fc10cd31010d6764896ab2423f56035bd",
            "timestamp": 1723321959,
            "prompt": [
                {
                    "role": "system",
                    "content": "This is a code completion task. Fill in code and output nothing else. Respect spacing, new lines, and indentation. Use XML notation (e.g. <DIV></DIV>). Start with <CODE>\n\nExample:\n<PREFIX>\nclass Calculator {\n  add(number) {\n    this.result += \n</PREFIX>\n<SUFFIX>\n  subtract(number) {\n    this.result -= number;\n    return this;\n  }\n}\n</SUFFIX>\n<CODE>\nnumber;\n    return this;\n  }\n</CODE>"
                },
                {
                    "role": "user",
                    "content": "Task:\n<PREFIX>\nimport os\nimport json\nimport pdb\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.image import imread\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom tqdm import tqdm\n\n# Load cached data\nif not os.path.exists(\\'../data\\'):\n    os.system(\\'gdown 1h7S6N_Rx7gdfO3ZunzErZy6H7620EbZK -O ../data.tar.gz\\')\n    os.system(\\'tar -xf ../data.tar.gz -C ../\\')\n    os.system(\\'rm ../data.tar.gz\\')\nif not os.path.exists(\\'../data/imagenet/human_readable_labels.json\\'):\n    !wget -nv -O ../data/imagenet/human_readable_labels.json -L https://raw.githubusercontent.com/anishathalye/imagenet-simple-labels/master/imagenet-simple-labels.json\n\ndata = np.load(\\'../data/imagenet/imagenet-resnet152.npz\\')\nexample_paths = os.listdir(\\'../data/imagenet/examples\\')\nsmx = data[\\'smx\\']\nlabels = data[\\'labels\\'].astype(int)\n\nidx = np.random.permutation(len(labels))\nlabels = labels[idx[:10000]]\nsmx = smx[idx[:10000]]\nprint(len(labels))\n\ndef get_thetahat_fixed(\n    h,\n    g,\n    p,\n    cost_ratio,\n    TOL=1e-20,\n):\n    xi = np.ones(len(h))\n    theta_hats = np.zeros(len(h))\n    costs = np.zeros(len(h))\n    for i in range(len(h)):\n        xi[i] = np.random.binomial(1, p)\n        costs[i] = costs[max(i-1,0)]\n        costs[i] += 1 if p == 1 else cost_ratio + xi[i]\n        theta_hats[i] = np.mean(g[:i] + (h[:i]-g[:i]) * xi[:i]/p) if i > 0 else 0\n    return theta_hats, costs\n\ndef optimal_p(VarH, EHG2, c_g, c_h, TOL=1e-20):\n    phat = np.clip(np.sqrt((c_g/c_h)/max(VarH/max(EHG2, TOL) - 1, TOL)),TOL,1)\n    return phat\n\ndef get_thetahat_active(\n    h,\n    g,\n    pis,\n    cost_ratio,\n    TOL=1e-20,\n):\n    # if pis is a float, call get_thetahat_fixed\n    if isinstance(pis, (int, float)):\n        return get_thetahat_fixed(h, g, pis, cost_ratio, TOL=TOL)\n    xi = np.ones(len(h))\n    theta_hats = np.zeros(len(h))\n    costs = np.zeros(len(h))\n    for i in range(len(h)):\n        xi[i] = np.random.binomial(1, pis[i])\n        costs[i] = costs[max(i-1,0)]\n        costs[i] += 1 if pis[i] == 1 else cost_ratio + xi[i]\n        theta_hats[i] = np.mean(g[:i] + (h[:i]-g[:i]) * xi[:i]/pis[:i]) if i > 0 else 0\n    return theta_hats, costs\n\ndef optimal_pi(u, VarH, EHG2, cost_ratio, TOL=1e-20):\n    phat = np.clip(np.sqrt(\n       np.maximum(u * cost_ratio / np.maximum(VarH - EHG2, TOL), TOL)\n    ),TOL,1)\n    return phat\n\n# Problem setup\nB = 1000\ncost_ratio = 0.01\nburnin = 100\nepsilon = 1e-20 # Min sampling probability\nTOL = 1e-20 # Numerical tolerance\nn = len(smx)\nnum_trials = 1000\nmethods = [\"oracle active\", \"optimal active\", \"optimal fixed\", 1, 0.5, 0.05]\n\ndf_list = []\nfor trial in tqdm(range(num_trials)):\n    np.random.seed(trial)\n    idx = np.random.permutation(n)\n    smx = smx[idx]\n    yhat = smx.argmax(axis=1)\n    labels = labels[idx]\n    h = (yhat == labels).astype(int)\n    g = smx.max(axis=1)\n    u = g*(1-g)\n    betas = np.linspace(0,1,10)\n    thetastar = (yhat == labels).mean()\n    for method in methods:\n        # Set random seed\n        np.random.seed(trial)\n        VarHhat = h[:burnin].var()\n        EHG2hat = ((h[:burnin] - g[:burnin])**2).mean()\n        if method == \"optimal fixed\":\n            phat = optimal_p(VarHhat, EHG2hat, cost_ratio, 1)\n        elif method == \"optimal active\": \n            phat = optimal_pi(u, VarHhat, EHG2hat, cost_ratio, TOL=TOL)\n        elif method == \"oracle active\":\n            phat = np.maximum((h-g)**2, TOL)\n        elif method == \"oracle mixing\":\n            phat_fixed = optimal_p(VarHhat, EHG2hat, cost_ratio, 1)\n            phat_active = optimal_pi(u, VarHhat, EHG2hat, cost_ratio, TOL=TOL)\n            phat = phat_fixed\n            best_mse = np.inf\n            for beta in betas:\n                _phat = beta*phat_fixed + (1-beta)*phat_active\n                _mse = (_phat.mean() + cost_ratio)*(VarHhat - EHG2hat + (((h[:burnin] - g[:burnin])**2)/_phat).mean())\n                if _mse \n</PREFIX>\n<SUFFIX>\n\n        else:\n            phat = method\n        th, costs = get_thetahat_active(h,g,phat,cost_ratio)\n        #th = get_thetahat(h,g,u,B,cost_ratio,burnin, pi_fixed=pi)\n        se = (th - thetastar)**2\n        for t in range(len(th)):\n            df_list.append({\n                \\'pi\\': phat if isinstance(phat, (int, float)) else phat[t],\n                \\'thetastar\\': thetastar,\n                \\'thetahat\\': th[t],\n                \\'se\\': se[t],\n                \\'cost\\': costs[t],\n                \\'method\\': method if isinstance(method, str) else f\"random ({int(100*method)}%)\",\n                \\'time\\': t,\n                \\'trial\\': trial,\n            })\n\ndf = pd.DataFrame(df_list)\n\ndf.to_parquet(\\'./trials.parquet\\')\n\ndf = pd.read_parquet(\\'./trials.parquet\\')\n\nto_plot = df.copy().drop([\\'pi\\', \\'thetastar\\', \\'thetahat\\'], axis=1)\nto_plot[\\'cost (rounded)\\'] = to_plot.cost.round(decimals=-1).astype(int)\nto_plot = to_plot.groupby([\\'method\\', \\'cost (rounded)\\'])[\\'se\\'].mean().reset_index()\nto_plot = to_plot[to_plot.method.isin([\n    \"random (100%)\", \"optimal fixed\", \"oracle active\", \"random (50%)\"\n])]\nto_plot = to_plot.replace({\"optimal fixed\" : \"optimal\", \"oracle active\" : \"oracle\"})\n\nsns.set()\nsns.set_style(\"whitegrid\")\nsns.set_context(\"talk\")\nplt.figure(figsize=(10,7))\npalette={\n    \"random (100%)\": \"steelblue\",\n    \"random (50%)\": \"lightsteelblue\",\n    \"random (5%)\": \"skyblue\",\n    \"optimal\": \"#FFA500\",\n    \"oracle\": \"darkgoldenrod\"\n}\nsns.lineplot(data=to_plot, x=\\'cost (rounded)\\', y=\\'se\\', hue=\\'method\\', errorbar=None, palette=palette)\nplt.xlim([200,1000])\nplt.ylim([0,0.001])\nplt.xlabel(\"Cost ($)\")\nplt.ylabel(\"MSE\")\n\n# For each squared error compute the mean cost for each method\nse_bins = np.linspace(0.0001, 0.0008, 100)\ndf_list = []\nfor method in to_plot.method.unique():\n    for se_bin in se_bins:\n        cost_for_se = to_plot[(to_plot.se <= se_bin) * (to_plot.method == method)][\\'cost (rounded)\\'].min()\n        cost_for_se_baseline = to_plot[(to_plot.se <= se_bin) * (to_plot.method == \"random (100%)\")][\\'cost (rounded)\\'].min()\n        df_list += [{\n            \"method\": method,\n            \"se\": se_bin,\n            \"cost\": cost_for_se,\n            \"cost ratio\": cost_for_se / cost_for_se_baseline,\n            \"cost difference\": cost_for_se_baseline - cost_for_se\n        }]\ndf_cost = pd.DataFrame(df_list)\n\ndf_cost = df_cost[df_cost.method != \"random (100%)\"]\nsns.set()\nsns.set_style(\"whitegrid\")\nsns.set_context(\"talk\")\nplt.figure(figsize=(10,7))\npalette={\n    \"random (100%)\": \"steelblue\",\n    \"random (50%)\": \"lightsteelblue\",\n    \"random (5%)\": \"skyblue\",\n    \"optimal\": \"#FFA500\",\n    \"oracle\": \"darkgoldenrod\"\n}\nsns.lineplot(data=df_cost, x=\\'se\\', y=\\'cost difference\\', hue=\\'method\\', errorbar=None, palette=palette)\nplt.xlabel(\"MSE\")\nplt.ylabel(\"Savings ($)\")\nplt.gca().invert_xaxis()\n\n\n</SUFFIX>"
                }
            ],
            "completion": "                < _mse:\n                best_mse = _mse\n                phat = _phat\n",
            "model": "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo"
        }
    ]
}